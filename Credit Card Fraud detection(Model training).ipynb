{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f6d24e",
   "metadata": {},
   "source": [
    "# Credit card fraud detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a42c9e",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1463ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba5d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f62370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "738a7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b723a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V21</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V14       V16  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.311169 -0.470401   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235 -0.143772  0.463917   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084 -0.165946 -2.890083   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228 -0.287924 -1.059647   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196 -1.119670 -0.451449   \n",
       "\n",
       "        V17       V18       V19       V21  Class  \n",
       "0  0.207971  0.025791  0.403993 -0.018307      0  \n",
       "1 -0.114805 -0.183361 -0.145783 -0.225775      0  \n",
       "2  1.109969 -0.121359 -2.261857  0.247998      0  \n",
       "3 -0.684093  1.965775 -1.232622 -0.108300      0  \n",
       "4 -0.237033 -0.038195  0.803487 -0.009431      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7d89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_frame.drop(['Class'],axis=1)\n",
    "y=data_frame[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22e02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b55f9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logisiticRegression\n",
    "log_model=LogisticRegression()\n",
    "log_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07b9e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992626663389628"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c18ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y=log_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2e61250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic regression\n",
      "\n",
      "True positive:  108\n",
      "True Negative:  85258\n",
      "False Postive:  49\n",
      "False Negative:  28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.69      0.79      0.74       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.84      0.90      0.87     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp=confusion_matrix(y_test,predicted_y).ravel()\n",
    "print('For Logistic regression')\n",
    "print('')\n",
    "print('True positive: ',tp)\n",
    "print('True Negative: ',tn)\n",
    "print('False Postive: ',fp)\n",
    "print('False Negative: ',fn)\n",
    "print('')\n",
    "print(classification_report(y_test,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f0d35ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990988144142879"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decisionTreeClassifier\n",
    "dt_model=DecisionTreeClassifier()\n",
    "dt_model.fit(x_train,y_train)\n",
    "dt_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2e28bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y=dt_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4704d079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For decision tree\n",
      "\n",
      "True positive:  108\n",
      "True Negative:  85258\n",
      "False Postive:  49\n",
      "False Negative:  28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.69      0.79      0.74       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.84      0.90      0.87     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp=confusion_matrix(y_test,predicted_y).ravel()\n",
    "print('For decision tree')\n",
    "print('')\n",
    "print('True positive: ',tp)\n",
    "print('True Negative: ',tn)\n",
    "print('False Postive: ',fp)\n",
    "print('False Negative: ',fn)\n",
    "print('')\n",
    "print(classification_report(y_test,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52a33249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/082wp8yj1vdb15yd5756bphm0000gn/T/ipykernel_3200/142543410.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_model.fit(x_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "rf_model=RandomForestClassifier()\n",
    "rf_model.fit(x_train,y_train)\n",
    "predicted_y=rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57cbe37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996488887328394\n"
     ]
    }
   ],
   "source": [
    "print(rf_model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "191d7de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For RandomForestClassifier\n",
      "\n",
      "True positive:  113\n",
      "True Negative:  85300\n",
      "False Postive:  7\n",
      "False Negative:  23\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.94      0.83      0.88       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.92      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp=confusion_matrix(y_test,predicted_y).ravel()\n",
    "print('For RandomForestClassifier')\n",
    "print('')\n",
    "print('True positive: ',tp)\n",
    "print('True Negative: ',tn)\n",
    "print('False Postive: ',fp)\n",
    "print('False Negative: ',fn)\n",
    "print('')\n",
    "print(classification_report(y_test,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "599a1966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999602073897218"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBClassifier\n",
    "xgb=XGBClassifier()\n",
    "xgb.fit(x_train,y_train)\n",
    "xgb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c2152b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y=xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcbabfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For XGBClassifier\n",
      "\n",
      "True positive:  110\n",
      "True Negative:  85299\n",
      "False Postive:  8\n",
      "False Negative:  26\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.93      0.81      0.87       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.90      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp=confusion_matrix(y_test,predicted_y).ravel()\n",
    "print('For XGBClassifier')\n",
    "print('')\n",
    "print('True positive: ',tp)\n",
    "print('True Negative: ',tn)\n",
    "print('False Postive: ',fp)\n",
    "print('False Negative: ',fn)\n",
    "print('')\n",
    "print(classification_report(y_test,predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee8e309",
   "metadata": {},
   "source": [
    "Accuaracies of all models are almost 1(100%) approx. But, in confusion matrix RandomForestRegressor has less false predictions than other models. So, RandomForestRegressor is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bac5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('pickle_model.pkl','wb') as file:\n",
    "    pickle.dump(rf_model,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
